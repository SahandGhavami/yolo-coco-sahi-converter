{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fb8e4f5f",
      "metadata": {},
      "source": [
        "## Step 1: YOLO to COCO Conversion\n",
        "### Configuration and Initialization\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7e1ef2b",
      "metadata": {},
      "source": [
        "Set up the data directory path and define your class mapping for the object detection task. \n",
        "            - Update `DATA_DIR` to point to your dataset folder containing `.jpg` images and `.txt` YOLO annotations.\n",
        "            - Modify `CLASS_MAPPING` to match your dataset's class IDs and names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f68fba8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "\n",
        "# Configuration: Data directory path\n",
        "# DATA_DIR = '/dataset/path'  # Parent directory containing images and annotations\n",
        "\n",
        "# Boats orientation class mapping\n",
        "CLASS_MAPPING = {\n",
        "    0: 'Small Craft', 1: 'Small Fishing Boat', 2: 'Small Passenger Ship',\n",
        "    3: 'Fishing Trawler', 4: 'Large Passenger Ship', 5: 'Sailing Boat',\n",
        "    6: 'Speed Craft', 7: 'Motorboat', 8: 'Pleasure Yacht',\n",
        "    9: 'Medium Ferry', 10: 'Large Ferry', 11: 'High Speed Craft'\n",
        "}\n",
        "\n",
        "print(\"YOLO to COCO Converter Initialized\")\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "print(f\"Data directory: {DATA_DIR}\")\n",
        "print(f\"Supporting {len(CLASS_MAPPING)} boats orientation classes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73e84471",
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_yolo_annotation(txt_file_path):\n",
        "    \"\"\"Parse YOLO format annotation file.\"\"\"\n",
        "    annotations = []\n",
        "    if not os.path.exists(txt_file_path):\n",
        "        return annotations\n",
        "        \n",
        "    with open(txt_file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        \n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            parts = line.split()\n",
        "            if len(parts) == 5:\n",
        "                class_id = int(parts[0])\n",
        "                x_center = float(parts[1])\n",
        "                y_center = float(parts[2])\n",
        "                width = float(parts[3])\n",
        "                height = float(parts[4])\n",
        "                \n",
        "                annotations.append({\n",
        "                    'class_id': class_id,\n",
        "                    'class_name': CLASS_MAPPING.get(class_id, f\"unknown_{class_id}\"),\n",
        "                    'x_center': x_center,\n",
        "                    'y_center': y_center,\n",
        "                    'width': width,\n",
        "                    'height': height\n",
        "                })\n",
        "    return annotations\n",
        "\n",
        "def yolo_to_coco_bbox(x_center, y_center, width, height, img_width, img_height):\n",
        "    \"\"\"Convert YOLO normalized coordinates to COCO bbox format.\"\"\"\n",
        "    # Convert from normalized to pixel coordinates\n",
        "    x_center_px = x_center * img_width\n",
        "    y_center_px = y_center * img_height\n",
        "    width_px = width * img_width\n",
        "    height_px = height * img_height\n",
        "    \n",
        "    # Convert to COCO format (top-left corner + width, height)\n",
        "    x_min = x_center_px - width_px / 2\n",
        "    y_min = y_center_px - height_px / 2\n",
        "    \n",
        "    return [x_min, y_min, width_px, height_px]\n",
        "\n",
        "print(\"YOLO parsing and COCO conversion functions loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55438efa",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_coco_dataset(image_dir = DATA_DIR, output_file='boat_annotations_coco.json'):\n",
        "    \"\"\"Create a complete COCO format dataset from YOLO annotations.\"\"\"\n",
        "    \n",
        "    coco_data = {\n",
        "        \"images\": [],\n",
        "        \"annotations\": [],\n",
        "        \"categories\": []\n",
        "    }\n",
        "    \n",
        "    # Add categories with supercategories\n",
        "    for class_id, class_name in CLASS_MAPPING.items():\n",
        "        vehicle_type = class_name.split('_')[0]  # car, bus, truck, etc.\n",
        "        coco_data[\"categories\"].append({\n",
        "            \"id\": class_id,\n",
        "            \"name\": class_name,\n",
        "            \"supercategory\": vehicle_type\n",
        "        })\n",
        "    \n",
        "    # Process images and annotations\n",
        "    jpg_files = glob.glob(os.path.join(image_dir, '*.jpg'))\n",
        "    annotation_id = 1\n",
        "    \n",
        "    print(f\"Processing {len(jpg_files)} images...\")\n",
        "    \n",
        "    for image_id, jpg_file in enumerate(jpg_files, 1):\n",
        "        try:\n",
        "            # Get image info\n",
        "            with Image.open(jpg_file) as img:\n",
        "                img_width, img_height = img.size\n",
        "                \n",
        "            # Add image info\n",
        "            image_name = os.path.basename(jpg_file)\n",
        "            coco_data[\"images\"].append({\n",
        "                \"id\": image_id,\n",
        "                \"width\": img_width,\n",
        "                \"height\": img_height,\n",
        "                \"file_name\": image_name,\n",
        "                \"license\": 1,\n",
        "                \"date_captured\": datetime.now().isoformat()\n",
        "            })\n",
        "            \n",
        "            # Process annotations\n",
        "            txt_file = jpg_file.replace('.jpg', '.txt')\n",
        "            if os.path.exists(txt_file):\n",
        "                annotations = parse_yolo_annotation(txt_file)\n",
        "                \n",
        "                for ann in annotations:\n",
        "                    bbox = yolo_to_coco_bbox(\n",
        "                        ann['x_center'], ann['y_center'], \n",
        "                        ann['width'], ann['height'],\n",
        "                        img_width, img_height\n",
        "                    )\n",
        "                    \n",
        "                    area = bbox[2] * bbox[3]  # width * height\n",
        "                    \n",
        "                    coco_data[\"annotations\"].append({\n",
        "                        \"id\": annotation_id,\n",
        "                        \"image_id\": image_id,\n",
        "                        \"category_id\": ann['class_id'],\n",
        "                        \"bbox\": bbox,\n",
        "                        \"area\": area,\n",
        "                        \"iscrowd\": 0,\n",
        "                        \"segmentation\": []  # Empty for bounding box detection\n",
        "                    })\n",
        "                    \n",
        "                    annotation_id += 1\n",
        "                    \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {jpg_file}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    # Save COCO dataset\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(coco_data, f, indent=2)\n",
        "    \n",
        "    return coco_data\n",
        "\n",
        "print(\"COCO dataset creation function ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f76012c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute COCO conversion\n",
        "print(\"Starting YOLO to COCO conversion...\")\n",
        "coco_dataset = create_coco_dataset()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"COCO CONVERSION COMPLETE\")\n",
        "print(\"=\"*50)\n",
        "print(f\"‚úÖ Images processed: {len(coco_dataset['images'])}\")\n",
        "print(f\"‚úÖ Annotations created: {len(coco_dataset['annotations'])}\")\n",
        "print(f\"‚úÖ Categories defined: {len(coco_dataset['categories'])}\")\n",
        "print(f\"‚úÖ Output file: boat_annotations_coco.json\")\n",
        "\n",
        "# Show sample data\n",
        "if coco_dataset['annotations']:\n",
        "    sample_annotation = coco_dataset['annotations'][0]\n",
        "    print(f\"\\nSample COCO annotation:\")\n",
        "    print(json.dumps(sample_annotation, indent=2))\n",
        "\n",
        "# Category summary\n",
        "print(f\"\\nCategories:\")\n",
        "for cat in coco_dataset['categories']:\n",
        "    print(f\"  {cat['id']}: {cat['name']} (supercategory: {cat['supercategory']})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35e9adbf",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "print(f\"üîç Testing DATA_DIR configuration:\")\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "print(f\"Data directory (DATA_DIR): {DATA_DIR}\")\n",
        "print(f\"Absolute path to data: {os.path.abspath(DATA_DIR)}\")\n",
        "\n",
        "# Check if data directory exists and list contents\n",
        "if os.path.exists(DATA_DIR):\n",
        "    print(f\"‚úÖ Data directory exists\")\n",
        "    jpg_files = glob.glob(os.path.join(DATA_DIR, '*.jpg'))\n",
        "    txt_files = glob.glob(os.path.join(DATA_DIR, '*.txt'))\n",
        "    print(f\"üì∑ Found {len(jpg_files)} .jpg files\")\n",
        "    print(f\"üìù Found {len(txt_files)} .txt files\")\n",
        "    \n",
        "    if jpg_files:\n",
        "        print(f\"üìã Sample images: {[os.path.basename(f) for f in jpg_files[:3]]}\")\n",
        "    if txt_files:\n",
        "        print(f\"üìã Sample annotations: {[os.path.basename(f) for f in txt_files[:3]]}\")\n",
        "else:\n",
        "    print(f\"‚ùå Data directory does not exist: {os.path.abspath(DATA_DIR)}\")\n",
        "    print(f\"üí° Please update DATA_DIR variable to point to your dataset location\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08fe7a6d",
      "metadata": {},
      "source": [
        "‚úÖ Attribution cell added to notebook!\n",
        "\n",
        "Attribution content:\n",
        "  - Original author: Raghav Dharwal\n",
        "  - Source: Kaggle notebook\n",
        "  - License: Apache 2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0df82e63",
      "metadata": {},
      "source": [
        "## Step 2: Slice with SAHI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3ab5a07",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install sahi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c083435",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "from sahi.slicing import slice_coco\n",
        "from sahi.utils.file import load_json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65f47df3",
      "metadata": {},
      "source": [
        "run this Python script to slice your images and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26d13ad6",
      "metadata": {},
      "outputs": [],
      "source": [
        "coco_dict, coco_path = slice_coco(\n",
        "    coco_annotation_file_path= \"/coco_annotation_file_path\",\n",
        "    image_dir= \"/image_dir_path\",\n",
        "    output_coco_annotation_file_name=\"sliced_coco_test.json\",\n",
        "    output_dir = \"/output_dir_path\",\n",
        "    slice_height=640, #set it as you want\n",
        "    slice_width=640,  #set it as you want\n",
        "    ignore_negative_samples=False,\n",
        "    overlap_height_ratio=0.2,\n",
        "    overlap_width_ratio=0.2,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47aa11c3",
      "metadata": {},
      "source": [
        "## Step 3: Convert Sliced COCO back to YOLO\n",
        "Once SAHI is done, you will have a new folder with sliced images and a new COCO JSON file. Use this script to turn that JSON into the YOLO .txt files you need for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9cd2520",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sahi.utils.coco import Coco\n",
        "\n",
        "json_path = \"/path/to/sliced_coco_test.json\"\n",
        "\n",
        "image_directory = \"/path/to/sliced/images/directory\"\n",
        "\n",
        "# Initialize Coco object\n",
        "coco = Coco.from_coco_dict_or_path(json_path, image_dir=image_directory)\n",
        "\n",
        "coco.export_as_yolo(\n",
        "  output_dir=\"\\output\\directory\\for\\yolo\\annotations\",\n",
        "  disable_symlink=True\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
